# Plan de Refactoring de Arquitectura - AI Chat Orchestrator

## 1. AnÃ¡lisis del Estado Actual

### 1.1 VersiÃ³n y Capacidades del SDK

**SDK Actual**: `@google/genai` versiÃ³n `1.9.0`

**MÃ©todos utilizados actualmente**:
```typescript
// En genaiService.ts
- ai.models.embedContent() // Para generar embeddings
- ai.models.generateContent() // Para generar respuestas

// ConfiguraciÃ³n actual
- Modelo generativo: gemini-2.0-flash-001
- Modelo embeddings: text-embedding-004
- Vertex AI: habilitado (vertexai: true)
```

**Capacidades del SDK identificadas**:
- âœ… GeneraciÃ³n de texto
- âœ… Embeddings
- âœ… Function calling (CONFIRMADO)
- âœ… Streaming (CONFIRMADO)
- âœ… Multimodal (audio) (CONFIRMADO)
- âœ… Automatic Function Calling (con control de max calls)
- âœ… Live API para conversaciones en tiempo real

### 1.2 Flujo Actual del Sistema

```
1. Usuario envÃ­a mensaje â†’ chatController
   â†“
2. handleChatPrompt (chatService.ts)
   â”œâ”€ Crear/obtener chat
   â”œâ”€ Guardar mensaje usuario
   â”œâ”€ Obtener historial (Ãºltimos 10)
   â”œâ”€ RAG Pipeline:
   â”‚  â”œâ”€ searchSimilarEmbeddingsVector (vector search)
   â”‚  â””â”€ buildAugmentedPrompt (construir prompt)
   â”œâ”€ aiGenerateContent (generar respuesta)
   â””â”€ Guardar respuesta
   â†“
3. Respuesta al usuario
```

**Tiempos actuales (aproximados)**:
- Vector search: ~200-300ms
- LLM generation: ~1-2s
- Total: ~2-3s por mensaje

### 1.3 Funcionalidades Actuales

**âœ… Funcionando correctamente (NO TOCAR)**:
- Chat creation/management
- Message persistence
- History retrieval
- Vector search bÃ¡sico
- Prompt augmentation
- Response generation

**ðŸ”„ Candidatos para refactoring**:
- SeparaciÃ³n de responsabilidades (todo en chatService)
- ConfiguraciÃ³n hardcodeada
- Sin abstracciÃ³n para LLM provider
- Sin soporte para streaming
- Sin preparaciÃ³n para multimodal (voz)

**ðŸ†• Nuevas features requeridas**:
- Soporte de voz (entrada/salida)
- Function calling
- Streaming responses
- Multi-tenant (MCP por centro)

## 2. Arquitectura Propuesta

### 2.1 Principios de DiseÃ±o

1. **No Breaking Changes**: Mantener funcionalidad actual
2. **Incremental Migration**: Cambios pequeÃ±os y validables
3. **Separation of Concerns**: Cada mÃ³dulo con responsabilidad Ãºnica
4. **Future Ready**: Preparado para voz y multi-tenant
5. **MCP First**: DiseÃ±ar para que cada centro tenga autonomÃ­a vÃ­a MCP
6. **Performance Oriented**: Optimizar para respuestas mÃ¡s rÃ¡pidas

### 2.2 Estructura de MÃ³dulos

```
src/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”œâ”€â”€ ChatManager.ts         # SOLO gestiÃ³n de chats
â”‚   â”‚   â”œâ”€â”€ MessageManager.ts      # SOLO gestiÃ³n de mensajes
â”‚   â”‚   â””â”€â”€ interfaces.ts          # Interfaces compartidas
â”‚   â”‚
â”‚   â”œâ”€â”€ conversation/
â”‚   â”‚   â”œâ”€â”€ ConversationOrchestrator.ts  # OrquestaciÃ³n principal
â”‚   â”‚   â”œâ”€â”€ HistoryManager.ts            # GestiÃ³n de historial
â”‚   â”‚   â””â”€â”€ PromptBuilder.ts             # ConstrucciÃ³n de prompts
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ RAGPipeline.ts         # Pipeline principal
â”‚   â”‚   â”œâ”€â”€ VectorSearcher.ts      # BÃºsqueda vectorial
â”‚   â”‚   â””â”€â”€ ContextAugmenter.ts    # AugmentaciÃ³n de contexto
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ interfaces.ts          # ILLMProvider
â”‚   â”‚   â”œâ”€â”€ GoogleGenAIProvider.ts # ImplementaciÃ³n actual
â”‚   â”‚   â””â”€â”€ StreamingHandler.ts    # Para streaming futuro
â”‚   â”‚
â”‚   â”œâ”€â”€ mcp/                       # NUEVO - Multi-tenant
â”‚   â”‚   â”œâ”€â”€ MCPAdapter.ts          # Adaptador MCP â†” Google GenAI
â”‚   â”‚   â”œâ”€â”€ MCPConnectionManager.ts # GestiÃ³n de conexiones por centro
â”‚   â”‚   â”œâ”€â”€ MCPToolCache.ts        # Cache de herramientas
â”‚   â”‚   â””â”€â”€ interfaces.ts          # Interfaces MCP
â”‚   â”‚
â”‚   â””â”€â”€ voice/                     # NUEVO - PreparaciÃ³n para voz
â”‚       â”œâ”€â”€ VoiceProcessor.ts      # Procesamiento de voz
â”‚       â”œâ”€â”€ AudioPipeline.ts       # Pipeline de audio
â”‚       â”œâ”€â”€ interfaces.ts          # Interfaces de voz
â”‚       â””â”€â”€ providers/             # Diferentes providers de voz
```

### 2.3 Fases de ImplementaciÃ³n

#### Fase 1: AnÃ¡lisis y PreparaciÃ³n (1 semana)
- [ ] Documentar SDK capabilities completas
- [ ] Crear tests de integraciÃ³n actuales (baseline)
- [ ] Medir performance actual
- [ ] Identificar dependencias exactas

#### Fase 2: AbstracciÃ³n LLM (1 semana)
- [ ] Crear interface ILLMProvider
- [ ] Implementar GoogleGenAIProvider
- [ ] Migrar genaiService a nuevo provider
- [ ] Validar que todo sigue funcionando

#### Fase 3: SeparaciÃ³n de Chat Logic (2 semanas)
- [ ] Extraer ChatManager
- [ ] Extraer MessageManager
- [ ] Crear ConversationOrchestrator
- [ ] Migrar chatService paso a paso

#### Fase 4: RAG Module (1 semana)
- [ ] Extraer RAGPipeline
- [ ] Separar VectorSearcher
- [ ] Implementar estrategias de bÃºsqueda

#### Fase 5: Voice Preparation (2 semanas)
- [ ] DiseÃ±ar interfaces de voz
- [ ] Crear VoiceProcessor bÃ¡sico
- [ ] Integrar con ConversationOrchestrator
- [ ] Tests con audio samples

#### Fase 6: Performance & Streaming (2 semanas)
- [ ] Implementar streaming en LLMProvider
- [ ] Optimizar vector search
- [ ] Caching strategy
- [ ] Response chunking

#### Fase 7: Multi-tenant con MCP (3 semanas)
- [ ] DiseÃ±ar adaptador MCP â†” Google GenAI
- [ ] Sistema de descubrimiento de servidores MCP por centro
- [ ] GestiÃ³n de conexiones MCP dinÃ¡micas
- [ ] Fallback cuando MCP no disponible
- [ ] Cache de herramientas por sesiÃ³n
- [ ] TraducciÃ³n bidireccional de formatos

## 3. PrÃ³ximos Pasos Inmediatos

### 3.1 InvestigaciÃ³n SDK (COMPLETADO) âœ…

**Hallazgos principales**:

#### Function Calling
```typescript
// SDK soporta function calling nativo
interface FunctionDeclaration {
  name: string;
  description?: string;
  parameters?: Schema;
  behavior?: Behavior; // NON_BLOCKING, etc.
}

// Automatic Function Calling
interface AutomaticFunctionCallingConfig {
  disable?: boolean;
  maximumRemoteCalls?: number; // Default: 10
  ignoreCallHistory?: boolean;
}

// Uso en config
config: {
  tools: [{ functionDeclarations: [myFunction] }],
  toolConfig: {
    functionCallingConfig: {
      mode: FunctionCallingConfigMode.AUTO, // AUTO, ANY, NONE
      allowedFunctionNames: ['function1', 'function2']
    }
  }
}
```

#### Streaming
```typescript
// MÃ©todos disponibles
chat.sendMessageStream() // Para chat streaming
models.generateContentStream() // Para generaciÃ³n streaming
apiClient.requestStream() // Para requests streaming
apiClient.processStreamResponse() // Para procesar responses
```

#### Audio/Multimodal
```typescript
// Interfaces para audio
interface AudioChunk {
  data?: string; // Base64 encoded
  mimeType?: string; // audio/mpeg, etc.
}

interface AudioTranscriptionConfig { }

// Live API para conversaciones en tiempo real
interface LiveConnectConfig {
  tools?: ToolListUnion;
  realtimeInputConfig?: RealtimeInputConfig;
}

// Soporte para audio en Parts
Part = {
  audioChunk?: AudioChunk;
  // ... otros tipos
}
```

### 3.2 Proof of Concepts Requeridos
1. **PoC Streaming**: Generar respuesta con streaming
2. **PoC Function Calling**: Llamar una funciÃ³n simple
3. **PoC Voice**: Procesar audio bÃ¡sico
4. **PoC Live API**: ConversaciÃ³n en tiempo real con voz

### 3.3 Arquitectura Multi-tenant con MCP

#### IntenciÃ³n General
Cada centro de distribuciÃ³n tendrÃ¡ su propio servidor MCP que expondrÃ¡ las herramientas y recursos especÃ­ficos de ese centro. El sistema de chat actuarÃ¡ como orquestador, conectÃ¡ndose al servidor MCP correspondiente segÃºn el centro del usuario.

#### Arquitectura de Proyectos GCP

**SeparaciÃ³n por Proyectos**:
- Cada centro de distribuciÃ³n serÃ¡ un proyecto GCP independiente
- Un proyecto GCP central Ãºnico para el Chat Orchestrator
- SeparaciÃ³n completa de recursos, datos y servicios por centro

**Lo que queremos en cada proyecto de CD**:
- Base de datos Firestore propia (historiales de chat, datos del negocio)
- Servidor MCP en Cloud Run (Node.js)
- Servicios de indexaciÃ³n propios
- Frontend propio (React o Pug engine)
- Embeddings y vectores locales al centro
- Integraciones especÃ­ficas del centro

**Lo que queremos en el proyecto Orchestrator**:
- Un Ãºnico servicio de chat centralizado
- GestiÃ³n de routing hacia los diferentes centros
- IdentificaciÃ³n automÃ¡tica del centro segÃºn el usuario
- Conexiones dinÃ¡micas a Firestore de cada CD
- Adaptador universal MCP â†” Google GenAI

#### Lo que queremos lograr:

**1. AutonomÃ­a por Centro de DistribuciÃ³n**
- Cada centro mantiene y evoluciona sus propias herramientas
- Los centros pueden agregar, modificar o eliminar funcionalidades sin afectar a otros
- Cada centro decide quÃ© integraciones necesita (SAP, sistemas locales, APIs especÃ­ficas)
- Datos completamente aislados por proyecto GCP

**2. IntegraciÃ³n MCP â†” Google GenAI SDK**
- El chat orchestrator debe poder descubrir herramientas disponibles desde cualquier servidor MCP
- Las herramientas MCP deben ser traducidas al formato que espera Google GenAI (FunctionDeclaration)
- Los resultados de Google GenAI deben ser traducidos de vuelta al formato MCP

**3. GestiÃ³n DinÃ¡mica de Conexiones**
- El sistema debe identificar el centro del usuario automÃ¡ticamente
- Debe establecer conexiÃ³n con el servidor MCP correcto
- Debe conectarse a la Firestore del proyecto GCP correspondiente
- Debe manejar casos donde el servidor MCP no estÃ© disponible

**4. Experiencia de Usuario Consistente**
- El usuario no debe notar diferencias tÃ©cnicas entre centros
- Las respuestas deben mantener el mismo tono y calidad
- Los tiempos de respuesta deben ser consistentes
- Un Ãºnico punto de entrada (orchestrator) para todos los usuarios

#### Flujo Conceptual Deseado:

1. **Usuario envÃ­a mensaje** â†’ Sistema identifica centro del usuario
2. **Sistema conecta con MCP del centro** â†’ Obtiene herramientas disponibles
3. **Sistema adapta herramientas MCP** â†’ Formato compatible con Google GenAI
4. **LLM procesa con herramientas del centro** â†’ Decide si usar alguna
5. **Sistema ejecuta herramientas vÃ­a MCP** â†’ El centro maneja la lÃ³gica
6. **Sistema recibe resultados** â†’ Los formatea para el usuario

#### Beneficios Esperados:

- **Escalabilidad organizacional**: Nuevos centros = nuevo proyecto GCP + MCP server
- **Mantenimiento distribuido**: Cada centro mantiene sus herramientas
- **EvoluciÃ³n independiente**: Centros pueden innovar sin coordinaciÃ³n central
- **ReducciÃ³n de complejidad central**: Chat orchestrator permanece simple
- **Aislamiento de datos**: Cumplimiento normativo y seguridad por diseÃ±o
- **Billing separado**: Cada centro ve y gestiona sus propios costos
- **Un Ãºnico servicio de chat**: Sin duplicaciÃ³n de cÃ³digo ni mantenimiento N veces

## 4. Riesgos y Mitigaciones

### Riesgo 1: Breaking changes
**MitigaciÃ³n**: 
- Tests exhaustivos antes de cada cambio
- Feature flags para rollback rÃ¡pido
- ValidaciÃ³n en staging primero

### Riesgo 2: Performance degradation
**MitigaciÃ³n**:
- Benchmarks antes/despuÃ©s
- Profiling de cada mÃ³dulo
- OptimizaciÃ³n incremental

### Riesgo 3: SDK limitations
**MitigaciÃ³n**:
- InvestigaciÃ³n profunda primero
- Plan B para cada feature
- AbstracciÃ³n que permita cambiar provider

## 5. Criterios de Ã‰xito

1. **Funcionalidad**: 100% feature parity con actual
2. **Performance**: â‰¤ latencia actual (idealmente -20%)
3. **Mantenibilidad**: CÃ³digo modular y testeable
4. **Extensibilidad**: FÃ¡cil agregar voz y multi-tenant

---

**Estado**: BORRADOR - Pendiente validaciÃ³n
**Ãšltima actualizaciÃ³n**: 2025-01-13