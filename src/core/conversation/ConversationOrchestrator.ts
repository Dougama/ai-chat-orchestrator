import { ChatMessage, MCPToolResult, ChatResponseWithData } from "../../types";
import { ChatRequest, ChatWithMessages } from "../chat/interfaces";
import { ChatManager } from "../chat/ChatManager";
import { MessageManager } from "../chat/MessageManager";
import { GoogleGenAIManager } from "../llm/GoogleGenAIManager";
import { MCPConnectionManager } from "../mcp/MCPConnectionManager";
import { MCPAdapter } from "../mcp/MCPAdapter";
import { MCPFallbackHandler } from "../mcp/MCPFallbackHandler";
import { MCPConnection } from "../mcp/interfaces";
import { Firestore } from "@google-cloud/firestore";
import { FunctionCallingConfigMode } from "@google/genai";
import { toolRegistry } from "../../tools/definitions/tool_registry";

export class ConversationOrchestrator {
  private static mcpConnectionManager = new MCPConnectionManager();
  private static mcpAdapter = new MCPAdapter();
  private static mcpFallbackHandler = new MCPFallbackHandler();

  /**
   * Maneja el flujo completo de conversaci贸n con soporte MCP
   * @param firestore Instancia de Firestore del centro
   * @param request Request de conversaci贸n
   * @param centerId ID del centro para conexi贸n MCP
   */
  static async handleChatPrompt(
    firestore: Firestore,
    request: ChatRequest,
    centerId?: string
  ): Promise<ChatResponseWithData> {
    const totalStartTime = Date.now();
    console.log(` Usuario: "${request.prompt}"`);

    let chatId = request.chatId;

    // 1. Si no hay chatId, creamos una nueva conversaci贸n
    let setupStartTime = Date.now();
    if (!chatId) {
      chatId = await ChatManager.createChat(
        firestore,
        request.prompt,
        request.userId || "anonymous"
      );
    }

    // 2. Guardamos el nuevo mensaje del usuario
    await MessageManager.saveUserMessage(firestore, chatId, request.prompt);

    // 3. Recuperamos el historial reciente para el contexto (aumentado para mejor continuidad)
    const history = await MessageManager.getRecentHistory(
      firestore,
      chatId,
      20
    );
    const setupTime = Date.now() - setupStartTime;
    console.log(`锔 Setup (Chat/Message/History): ${setupTime}ms`);

    // 4. Preparamos TODAS las herramientas (internas + MCP) antes del an谩lisis
    const toolsStartTime = Date.now();
    let tools: any[] = [];
    let mcpConnection: MCPConnection | null = null;

    // Agregar herramientas internas (excluyendo RAG)
    const internalTools = this.getInternalTools().filter(
      (tool) => tool.name !== "buscar_informacion_operacional"
    );
    tools.push(...internalTools);

    // Agregar herramientas MCP
    if (centerId) {
      try {
        // Intentar conectar a MCP del centro
        mcpConnection = await this.mcpConnectionManager.connectToCenter(
          centerId
        );

        if (mcpConnection.isConnected) {
          // Obtener herramientas disponibles del centro
          const mcpTools = await this.mcpConnectionManager.getAvailableTools(
            centerId
          );
          const validTools = this.mcpAdapter.filterValidMCPTools(mcpTools);

          if (validTools.length > 0) {
            // Convertir herramientas MCP a formato Google GenAI
            const mcpGenAITools =
              this.mcpAdapter.convertMCPToolsToGenAI(validTools);
            tools.push(...mcpGenAITools);
          }
        }
      } catch (error) {
        // Continuar sin herramientas MCP
      }
    }
    const toolsTime = Date.now() - toolsStartTime;
    console.log(
      ` Preparaci贸n herramientas (${tools.length} total): ${toolsTime}ms`
    );

    // 5. LLM1: An谩lisis RAG especializado
    const ragStartTime = Date.now();
    const ragResults = await this.executeRAGAnalysis(
      request.prompt,
      history,
      centerId || "bogota",
      firestore,
      chatId
    );
    const ragTime = Date.now() - ragStartTime;
    console.log(
      ` An谩lisis RAG: ${ragTime}ms${
        ragResults.executed ? " (ejecutado)" : " (no necesario)"
      }`
    );

    // 6. MODO NATIVO: LLM2 con herramientas MCP + contexto RAG
    const nativeStartTime = Date.now();

    // Convertir historial a formato nativo del SDK, incluyendo resultados RAG si existen
    const contents = this.formatHistoryForNativeSDK(
      history,
      request.prompt,
      ragResults
    );

    const llmProvider = GoogleGenAIManager.getProvider(
      centerId || "default",
      firestore
    );

    const nativeResponse = await llmProvider.generateContent({
      contents,
      trackTokens: true,
      chatId: chatId,
      tools: tools.length > 0 ? [{ functionDeclarations: tools }] : undefined,
      toolConfig: {
        functionCallingConfig: {
          mode: FunctionCallingConfigMode.AUTO,
        },
      },
      config: {
        temperature: 0.7,
        maxOutputTokens: 3500,
        topK: 40,
        topP: 0.95,
        systemInstruction: `
        Fecha y hora actual: ${new Date().toISOString()}

        Eres Chelita, una asistente inteligente, amable y eficiente. Servicial y muy dispuesta a ayudar.
        Sabes explicar muy bien las cosas y siempre buscas la mejor soluci贸n.
        Tu objetivo es ayudar al usuario a resolver su consulta de la mejor manera posible en un lenguajo no muy tecnico.
        Olvida codigo o nombres de funciones o parametros, usa un lenguaje natural y amigable.
        las herramientas son tus capacidades y no algo a lo que te debas referir como ajeno.

        las herramientas tienen descripciones que te ayudan a entender para que sirven. Analiza cuales parametros son requerido y cuales son opcionales..
        no inventes datos ni uses valores gen茅ricos, usa los datos que te dan las herramientas
        no solicites al usuario parametros exactos brindale una solicitud intepretada por ti de lo que se requiere

        Analiza los resultados de las erramientas asegurate de tener todos los parametros necesarios para decidir ejecutar una herramienta.
        Si no los tienes pregunta o validalos con el usuario.
        
        ${
          ragResults?.executed && ragResults.result
            ? `
        # BASE DEL CONOCIMIENTO:
        ${JSON.stringify(ragResults.result.response, null, 2)}
        
        INSTRUCCIN IMPORTANTE: Si existe la base del conocimiento arriba y tiene relaci贸n con lo que pregunta el usuario seg煤n el historial y su 煤ltimo mensaje, entonces responde basado en esa informaci贸n. Si no tiene relaci贸n o no existe, contin煤a decidiendo lo que consideres apropiado, ya sea ejecutar herramientas o responder de otra manera.
        `
            : ""
        }
        `,
      },
    });

    const nativeTime = Date.now() - nativeStartTime;
    console.log(` Modo Nativo (todo integrado): ${nativeTime}ms`);

    // Procesar function calls si existen
    let functionCallResults: any[] = [];
    if (
      nativeResponse.functionCalls &&
      nativeResponse.functionCalls.length > 0
    ) {
      console.log(
        ` Function calls ejecutadas: ${nativeResponse.functionCalls
          .map((f) => f.name)
          .join(", ")}`
      );
      functionCallResults = await this.processFunctionCalls(
        firestore,
        chatId,
        centerId || "bogota",
        nativeResponse.functionCalls,
        mcpConnection
      );
    }

    const assistantText = nativeResponse.text || "";

    // 7. Preparar datos MCP desde function calls
    const mcpData: MCPToolResult[] = functionCallResults
      .filter((result: any) => result.name !== "buscar_informacion_operacional") // Excluir RAG
      .map((result: any) => {
        const toolResult: MCPToolResult = {
          toolName: result.name,
          callId:
            result.callId ||
            `call_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
          success: result.success !== false && !result.error,
          data: {
            params: result.response?.params || {},
            totalRegistros:
              result.response?.total_registros ||
              result.response?.totalCount ||
              result.response?.totalRegistros ||
              0,
          },
        };

        // Agregar error si existe
        if (result.error) {
          toolResult.error = result.error;
          toolResult.success = false;
        }

        return toolResult;
      });

    // 8. Preparar toolData para contexto nativo del historial (excluyendo RAG)
    const toolDataForHistory = functionCallResults
      .filter((result: any) => result.name !== "buscar_informacion_operacional") // Excluir RAG
      .reduce((acc, result) => {
        acc[result.name] = result.response || {}; // Solo datos/resultados de la respuesta MCP
        return acc;
      }, {} as { [toolName: string]: any });


    // 9. Guardamos la respuesta del asistente con data y toolData
    const saveStartTime = Date.now();
    const assistantDocId = await MessageManager.saveAssistantMessage(
      firestore,
      chatId,
      assistantText,
      mcpData.length > 0 ? mcpData : undefined,
      Object.keys(toolDataForHistory).length > 0
        ? toolDataForHistory
        : undefined
    );

    // 11. Actualizamos la fecha del chat
    await ChatManager.updateChatTimestamp(firestore, chatId);
    const saveTime = Date.now() - saveStartTime;
    console.log(` Guardar respuesta: ${saveTime}ms`);

    // 12. Tiempo total de la funci贸n
    const totalTime = Date.now() - totalStartTime;
    console.log(
      `憋 TIEMPO TOTAL handleChatPrompt: ${totalTime}ms (${(
        totalTime / 1000
      ).toFixed(2)}s)`
    );

    // 13. Devolvemos la respuesta con campo data[] si hay resultados MCP
    const responseData: ChatResponseWithData = {
      id: assistantDocId,
      role: "assistant" as const,
      content: assistantText,
      timestamp: new Date(),
      chatId: chatId,
      ...(mcpData.length > 0 && { data: mcpData }),
    };

    return responseData;
  }

  /**
   * Procesa function calls ejecut谩ndolas (internas o MCP)
   */
  private static async processFunctionCalls(
    firestore: Firestore,
    chatId: string,
    centerId: string,
    functionCalls: any[],
    mcpConnection: MCPConnection | null
  ): Promise<any[]> {
    const results: any[] = [];

    for (const functionCall of functionCalls) {
      try {
        const toolName = functionCall.name;
        const callParams = this.extractToolCallParams(functionCall);

        // Verificar tipo de herramienta y procesar seg煤n corresponda
        const isInternalTool = this.isInternalTool(toolName);

        if (isInternalTool) {
          const result = await this.processInternalToolCall(
            firestore,
            chatId,
            centerId,
            functionCall,
            callParams
          );
          if (result) results.push(result);
        } else {
          const result = await this.processMCPToolCall(
            centerId,
            functionCall,
            callParams,
            mcpConnection
          );
          if (result) results.push(result);
        }
      } catch (error) {
        // Continuar con otros function calls
      }
    }

    return results;
  }

  /**
   * Versi贸n simplificada para compatibilidad con c贸digo existente
   */
  static async handleChatPromptSimple(
    firestore: Firestore,
    request: ChatRequest
  ): Promise<ChatResponseWithData> {
    return await this.handleChatPrompt(firestore, request);
  }

  /**
   * Obtiene herramientas internas disponibles en formato Google GenAI
   */
  private static getInternalTools(): any[] {
    const internalTools: any[] = [];

    // Iterar sobre herramientas locales del registry
    Object.values(toolRegistry).forEach((tool) => {
      if (tool.type === "LOCAL") {
        // Convertir definici贸n a formato Google GenAI
        internalTools.push({
          name: tool.definition.name,
          description: tool.definition.description,
          parameters: tool.definition.parameters,
        });
      }
    });

    return internalTools;
  }

  /**
   * Extrae par谩metros de una llamada de funci贸n para guardar en toolCalls
   */
  private static extractToolCallParams(functionCall: any): any {
    return functionCall.args || functionCall.parameters || {};
  }

  /**
   * Ejecuta una herramienta interna
   */
  private static async executeInternalTool(
    firestore: Firestore,
    chatId: string,
    centerId: string,
    toolName: string,
    callParams: any
  ): Promise<any> {
    try {
      // Importar din谩micamente el handler RAG
      if (toolName === "buscar_informacion_operacional") {
        const { executeRAGSearch } = await import(
          "../../tools/implementations/local/ragSearch"
        );

        // Usar centerId del par谩metro

        const result = await executeRAGSearch(
          firestore,
          chatId,
          centerId,
          callParams
        );

        return {
          name: toolName,
          response: {
            ...result,
            params: callParams,
          },
        };
      }

      return null;
    } catch (error) {
      return {
        name: toolName,
        response: {
          success: false,
          error: error instanceof Error ? error.message : "Error desconocido",
        },
      };
    }
  }

  /**
   * Verifica si una herramienta es interna
   */
  private static isInternalTool(toolName: string): boolean {
    return Object.values(toolRegistry).some(
      (tool) => tool.type === "LOCAL" && tool.definition.name === toolName
    );
  }

  /**
   * Procesa una herramienta interna
   */
  private static async processInternalToolCall(
    firestore: Firestore,
    chatId: string,
    centerId: string,
    functionCall: any,
    callParams: any
  ): Promise<any> {
    return await this.executeInternalTool(
      firestore,
      chatId,
      centerId,
      functionCall.name,
      callParams
    );
  }

  /**
   * Procesa una herramienta MCP
   */
  private static async processMCPToolCall(
    centerId: string,
    functionCall: any,
    callParams: any,
    mcpConnection: MCPConnection | null
  ): Promise<any> {
    // Convertir function call a formato MCP
    const mcpToolCalls = this.mcpAdapter.convertGenAIResultsToMCP([
      functionCall,
    ]);

    if (mcpToolCalls.length === 0) return null;

    const mcpToolCall = mcpToolCalls[0];
    let toolResult;

    // Ejecutar herramienta MCP
    if (mcpConnection?.isConnected) {
      toolResult = await this.mcpConnectionManager.executeToolCall(
        centerId,
        mcpToolCall
      );
    } else {
      toolResult = await this.mcpFallbackHandler.executeFallbackTool(
        mcpToolCall
      );
    }

    // Convertir resultado de vuelta a formato GenAI
    const genAIResult = this.mcpAdapter.convertMCPResultsToGenAI([toolResult]);

    if (genAIResult.length > 0) {
      console.log(`ConversationOrchestrator: MCP tool result:`, {
        toolName: functionCall.name,
        success: toolResult.success,
        hasData: !!toolResult.data,
      });

      return {
        ...genAIResult[0],
        response: {
          ...genAIResult[0].response,
          params: callParams,
        },
      };
    }

    return null;
  }

  /**
   * KISS: Int茅rprete de herramientas simple - EJECUTA herramientas y retorna datos
   */
  private static async executeToolInterpreter(
    prompt: string,
    tools: any[],
    history: any[],
    centerId: string,
    firestore: Firestore,
    chatId: string,
    mcpConnection: any
  ): Promise<{ data: string; results: any[] }> {
    const toolInterpreterStartTime = Date.now();
    const toolPrompt = `
    Eres un interprete en una conversacion (chat) entre un asistente y un usuario
    Tu trabajo es analizar el mensaje del usuario para entender su relaci贸n con el historial
    y las herramientas disponibles segun su descripci贸n para determinar la intenci贸n mas probable y definir con criterio
    lo que el usuario quiere lograr. y si una herramienta es necesaria o no.
    

    Ejecuta las herramientas necesarias considerando el contexto temporal y conversacional.
    por favor analiza profundamente Si algun parametro requerido para una herramienta falta, no debes ejecutarla.
    La unica condicion para ejecutar una herramienta es que exista una relacion semantica entre el mensaje del usuario
    las herramientas disponibles y el historial reciente de la conversacion.
    <HISTORIAL_RECIENTE_DE_CONVERSACION>
      ${MessageManager.formatHistoryForLLM(history.slice(-5))}
    </HISTORIAL_RECIENTE_DE_CONVERSACION>
    <MENSAJE_DEL_USUARIO>
    "${prompt}"
    </MENSAJE_DEL_USUARIO>
    <HERRAMIENTAS> 
      ${tools.map((t) => `- ${t.name}: ${t.description}`).join("\n")}
    </HERRAMIENTAS>


   SOLO ejecutar herramientas si TODOS los par谩metros requeridos est谩n disponibles
   Si falta alg煤n par谩metro requerido, NO ejecutar la herramienta
    NO inventar datos ni usar valores gen茅ricos
    
`;

    // Usar modelo LITE (Flash)
    const llmProvider = GoogleGenAIManager.getProvider(centerId, firestore);
    const response = await llmProvider.generateContent({
      prompt: toolPrompt,
      trackTokens: true,
      chatId: chatId + "_tools",
      tools: [{ functionDeclarations: tools }],
      toolConfig: {
        functionCallingConfig: {
          mode: FunctionCallingConfigMode.ANY,
        },
      },
      config: {
        temperature: 0.1, // Muy determin铆stico
        maxOutputTokens: 2000,
        topK: 10,
        topP: 0.7,
      },
    });

    // Procesar herramientas ejecutadas
    let results: any[] = [];
    if (response.functionCalls && response.functionCalls.length > 0) {
      console.log(
        ` ToolInterpreter FUNCTIONS: ${response.functionCalls
          .map((f) => f.name)
          .join(", ")} herramientas ejecutadas`
      );
      // Procesar cada llamada de funci贸n
      results = await this.processFunctionCalls(
        firestore,
        chatId,
        centerId,
        response.functionCalls,
        mcpConnection
      );
    }

    const data =
      results.length > 0
        ? results
            .map((r) => `${r.name}: ${JSON.stringify(r.response)}`)
            .join("\n")
        : "No se ejecutaron herramientas";

    return { data, results };
  }

  /**
   * LLM1: An谩lisis especializado para decidir si ejecutar RAG
   */
  private static async executeRAGAnalysis(
    prompt: string,
    history: any[],
    centerId: string,
    firestore: Firestore,
    chatId: string
  ): Promise<{ executed: boolean; data?: string; result?: any }> {
    // Obtener solo la herramienta RAG
    const ragTool = this.getInternalTools().find(
      (tool) => tool.name === "buscar_informacion_operacional"
    );
    if (!ragTool) {
      return { executed: false };
    }

    // Crear contenido nativo para an谩lisis RAG (sin recursi贸n)
    const ragContents: any[] = [];

    // Agregar historial b谩sico
    history.slice(-10).forEach((message) => {
      if (message.role === "user" || message.role === "assistant") {
        ragContents.push({
          role: message.role === "assistant" ? "model" : message.role,
          parts: [{ text: message.content }],
        });
      }
    });

    const llmProvider = GoogleGenAIManager.getProvider(centerId, firestore);

    const ragResponse = await llmProvider.generateContent({
      contents: ragContents,
      trackTokens: true,
      chatId: chatId + "_rag",
      tools: [{ functionDeclarations: [ragTool] }],
      toolConfig: {
        functionCallingConfig: {
          mode: FunctionCallingConfigMode.AUTO,
        },
      },
      config: {
        temperature: 0.2, // M谩s determin铆stico para decisiones
        maxOutputTokens: 1500,
        topK: 20,
        topP: 0.8,
        systemInstruction: `Eres un revisor que analiza si para responder a seg煤n el mensaje m谩s reciente del usuario necesitas buscar informaci贸n t茅cnica espec铆fica sobre procesos, procedimientos, documentaci贸n o datos que no est谩n en tu conocimiento base.

IMPORTANTE: Solo usa la herramienta de b煤squeda si:
- El usuario pregunta sobre procesos espec铆ficos de la empresa
- Necesitas documentaci贸n t茅cnica actual
- Requieres datos operacionales espec铆ficos
- La pregunta es sobre procedimientos internos

NO uses la herramienta si:
- Es conversaci贸n casual
- Preguntas generales que puedes responder

Si decides buscar, hazlo. Si no, responde normalmente.`,
      },
    });

    // Si ejecut贸 la herramienta RAG
    if (ragResponse.functionCalls && ragResponse.functionCalls.length > 0) {
      const ragFunctionCall = ragResponse.functionCalls[0];
      const ragResult = await this.executeInternalTool(
        firestore,
        chatId,
        centerId,
        ragFunctionCall.name,
        ragFunctionCall.args || ragFunctionCall.parameters || {}
      );

      return {
        executed: true,
        data: ragResult?.response
          ? JSON.stringify(ragResult.response)
          : "Sin datos RAG",
        result: ragResult,
      };
    }

    return { executed: false };
  }

  /**
   * Convierte historial a formato nativo del SDK con contexto de herramientas y RAG
   */
  private static formatHistoryForNativeSDK(
    history: any[],
    currentPrompt: string,
    ragResults?: { executed: boolean; data?: string; result?: any }
  ): any[] {
    const contents: any[] = [];

    // Reconstruir el historial manteniendo la secuencia correcta (sin mensajes system)
    history.slice(-15).forEach((message) => {
      // Saltar mensajes system - Google GenAI no los acepta
      if (message.role === "system") return;

      // Agregar mensaje del usuario
      if (message.role === "user") {
        contents.push({
          role: "user",
          parts: [{ text: message.content }],
        });
      }

      // Para mensajes del asistente
      if (message.role === "assistant") {
        // Si us贸 herramientas, reconstruir la secuencia completa
        if (message.toolData && Object.keys(message.toolData).length > 0) {
          // 1. Agregar los function calls del modelo
          const functionCalls = Object.entries(message.toolData).map(
            ([toolName, data]: [string, any]) => ({
              functionCall: {
                name: toolName,
                args: data.params || data.args || {},
              },
            })
          );

          contents.push({
            role: "model",
            parts: functionCalls,
          });

          // 2. Agregar los resultados de las funciones
          const functionResponses = Object.entries(message.toolData).map(
            ([toolName, data]: [string, any]) => ({
              functionResponse: {
                name: toolName,
                response: data.result || data,
              },
            })
          );

          contents.push({
            role: "function",
            parts: functionResponses,
          });
        }

        // 3. Siempre agregar la respuesta final del modelo
        contents.push({
          role: "model",
          parts: [{ text: message.content }],
        });
      }
    });

    // 3. Prompt actual del usuario (limpio, sin modificaciones)
    contents.push({
      role: "user",
      parts: [{ text: currentPrompt }],
    });

    return contents;
  }

  /**
   * KISS: Int茅rprete de intenci贸n simple - RETORNA texto explicativo
   */
  private static async executeIntentionInterpreter(
    prompt: string,
    tools: any[],
    history: any[],
    centerId: string,
    firestore: Firestore
  ): Promise<string> {
    const intentionPrompt = `
    Eres un interprete en una conversacion (chat) entre un asistente y un usuario Tu trabajo es analizar el mensaje del usuario para entender su relaci贸n con el historial
    y las herramientas disponibles segun su descripci贸n para determinar la intenci贸n mas probable y definir con criterio
    lo que el usuario quiere lograr. y si una herramienta es necesaria o no.
    tu respuesta debe ser siempre en el mismo formato
    por favor analiza profundamente Si algun parametro requerido para una herramienta falta, sugiere pedir el dato.
    En caso del que no tengas claro la intencion del usuario, mira si el mensaje, revisa similitudes entre palabras claves entre las herramientas y lo que pide el usuario. 

    breve explicacion en una lista aparte una lista tipo
    - Herramienta A
    - Herramienta B
    etc de las que consideres que son necesarias para resolver la consulta del usuario.
    y listo. Eres un experto en esto tu volmen de fallos es casi 0.
    <HISTORIAL_RECIENTE_DE_CONVERSACION>
      ${MessageManager.formatHistoryForLLM(history.slice(-5))}
    </HISTORIAL_RECIENTE_DE_CONVERSACION>
    <MENSAJE_DEL_USUARIO>
    "${prompt}"
    </MENSAJE_DEL_USUARIO>
    <HERRAMIENTAS> 
      ${tools.map((t) => `- ${t.name}: ${t.description}`).join("\n")}
    </HERRAMIENTAS>

 
    hora y fecha actual
    ${new Date().toISOString()}
    

`;
    const llmProvider = GoogleGenAIManager.getProvider(centerId, firestore);
    const response = await llmProvider.generateContent({
      prompt: intentionPrompt,
      trackTokens: false,
      toolConfig: {
        functionCallingConfig: {
          mode: FunctionCallingConfigMode.NONE,
        },
      },
      config: {
        temperature: 0.3,
        maxOutputTokens: 1000,
        topK: 20,
        topP: 0.8,
      },
    });
    // console.log("RESPONSE INTENTION INTERPRETER:", response);
    return response.text;
  }
}
