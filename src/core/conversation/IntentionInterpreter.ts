/**
 * Int√©rprete de intenciones que usa LLM para enriquecer prompts del usuario
 * cuando detecta necesidad de b√∫squeda operacional
 */
import { ChatMessage } from "../../types";
import { GoogleGenAIManager } from "../llm/GoogleGenAIManager";
import { Firestore } from "@google-cloud/firestore";

interface MCPTool {
  name: string;
  description: string;
  parameters?: any;
}

export class IntentionInterpreter {
  /**
   * Enriquece el prompt del usuario usando LLM para detectar intenci√≥n de b√∫squeda
   * @param originalPrompt Prompt original del usuario
   * @param centerId ID del centro para LLM
   * @param availableMCPTools Lista de herramientas MCP disponibles
   * @param firestore Instancia de Firestore
   * @returns Objeto con prompt original, instrucci√≥n enriquecida y tipo de herramienta
   */
  static async enhanceUserPrompt(
    originalPrompt: string,
    centerId: string,
    availableTools: any[] = [], // Ahora recibe herramientas en formato GenAI
    history: ChatMessage[] = [],
    firestore?: Firestore
  ): Promise<{
    originalPrompt: string;
    enhancedInstruction?: string;
    toolType?: string;
  }> {
    try {
      // Detectar intenci√≥n y determinar si requiere enriquecimiento
      const analysisResult = await this.detectAndEnhanceWithLLM(
        originalPrompt,
        centerId,
        availableTools,
        history,
        firestore
      );
      if (!analysisResult.requiresSearch) {
        console.log(
          `üí¨ IntentionInterpreter: Consulta directa - no requiere herramientas`
        );
        return { originalPrompt };
      }
      // Retornar objeto con toda la informaci√≥n
      console.log(
        `‚úÖ IntentionInterpreter: Ejecutando ${analysisResult.toolType} - ${analysisResult.reasoning}`
      );

      return {
        originalPrompt,
        enhancedInstruction: analysisResult.enhancedInstruction,
        toolType: analysisResult.toolType,
      };
    } catch (error) {
      console.error(
        "‚ùå IntentionInterpreter: Error en an√°lisis, usando prompt original:",
        error
      );
      return { originalPrompt };
    }
  }

  /**
   * Usa LLM para detectar intenci√≥n y generar instrucci√≥n enriquecida
   */
  private static async detectAndEnhanceWithLLM(
    prompt: string,
    centerId: string,
    availableTools: any[],
    history: ChatMessage[],
    firestore?: Firestore
  ): Promise<{
    toolType: any;
    requiresSearch: boolean;
    enhancedInstruction?: string;
    reasoning: string;
  }> {
    // Construir lista de herramientas disponibles
    const recentContext =
      history
        ?.slice(-7)
        .map(
          (msg) =>
            `${msg.role === "user" ? "Usuario" : "Asistente"}: ${msg.content}`
        )
        .join("\n") || "Sin historial previo";

    const mcpTools = availableTools;

    const mcpToolsList =
      mcpTools.length > 0
        ? mcpTools
            .map((tool) => `- ${tool.name}: ${tool.description}`)
            .join("\n")
        : "No hay herramientas MCP disponibles";
    console.log(
      `üß† IntentionInterpreter: Analizando intenci√≥n para "${prompt} en detectAndEnhanceWithLLM"`,
      `Herramientas disponibles: ${availableTools
        .map((tool) => tool.name)
        .join(", ")}`
    );
    const analysisPrompt = `
Eres un ANALIZADOR DE INTENCIONES especializado en clasificar consultas de usuarios y determinar la herramienta m√°s apropiada para responder.

## CONTEXTO CONVERSACIONAL RECIENTE
${recentContext}
## IMPORTANTE: AN√ÅLISIS CONTEXTUAL
- Si la consulta contiene referencias de√≠cticas ("este", "eso", "y"), DEBES usar el contexto previo
- Si la consulta es ambigua sin contexto, indica que necesitas m√°s informaci√≥n
- NO asumas herramientas bas√°ndote solo en palabras sueltas

## CONTEXTO
Tienes acceso a herramientas MCP din√°micas y una herramienta interna de b√∫squeda documental. Tu tarea es analizar cada consulta y decidir qu√© herramienta usar (o si no necesita ninguna).

## CONSULTA A ANALIZAR
"${prompt}"

## HERRAMIENTAS DISPONIBLES

### HERRAMIENTAS MCP (Datos Din√°micos)
${mcpToolsList}

### HERRAMIENTA INTERNA (B√∫squeda Documental)
- **buscar_informacion_operacional**: Accede a manuales, protocolos, pol√≠ticas, procedimientos y documentaci√≥n operacional empresarial

## REGLAS DE CLASIFICACI√ìN

### 1. USA HERRAMIENTA MCP cuando:
- La consulta requiere datos espec√≠ficos en tiempo real
- Se mencionan identificadores concretos (c√©dulas, IDs, fechas)
- Se solicitan m√©tricas, rendimientos o estad√≠sticas actuales
- La consulta implica operaciones con datos din√°micos

### 2. USA HERRAMIENTA INTERNA cuando:
- Se pregunta "¬øC√≥mo hacer...?" o "¬øQu√© requisitos...?"
- Se solicita informaci√≥n sobre procesos o procedimientos
- Se necesitan pol√≠ticas, normativas o protocolos
- Se busca informaci√≥n t√©cnica de manuales operacionales

### 3. NO USES HERRAMIENTAS cuando:
- Son saludos, despedidas o expresiones de cortes√≠a
- Conversaci√≥n casual sin solicitud de informaci√≥n
- Preguntas sobre el asistente o sus capacidades

## POL√çTICA DE CONSULTAS REPETIDAS
‚ö†Ô∏è IMPORTANTE: Siempre ejecuta la herramienta aunque la consulta sea repetida
- Los datos operacionales cambian constantemente
- Los usuarios frecuentemente necesitan informaci√≥n actualizada
- Cada consulta debe tratarse como nueva

## FORMATO DE RESPUESTA REQUERIDO
Responde √öNICAMENTE con este JSON estructurado:

{
  "requiresSearch": true/false,
  "toolType": "MCP" | "INTERNAL" | "NONE",
  "enhancedInstruction": "Instrucci√≥n detallada y espec√≠fica para ejecutar la herramienta correcta (solo si requiresSearch=true)",
  "reasoning": "Explicaci√≥n concisa de la decisi√≥n tomada"
}

## EJEMPLOS DE REFERENCIA

### Ejemplo MCP - Consulta de datos espec√≠ficos:
Input: "Consulta los rendimientos de la c√©dula 1140845095 para julio"
Output: {
  "requiresSearch": true,
  "toolType": "MCP",
  "enhancedInstruction": "Utiliza la herramienta MCP de consulta de rendimientos para obtener los datos espec√≠ficos de la c√©dula 1140845095 correspondientes al per√≠odo de julio del a√±o actual",
  "reasoning": "Solicitud de datos din√°micos con identificador espec√≠fico (c√©dula) y per√≠odo temporal definido"
}

### Ejemplo INTERNAL - Informaci√≥n procedimental:
Input: "¬øQu√© sabes sobre el alquiler de ocasionales?"
Output: {
  "requiresSearch": true,
  "toolType": "INTERNAL",
  "enhancedInstruction": "Busca en la documentaci√≥n operacional toda la informaci√≥n disponible sobre el proceso de alquiler de veh√≠culos ocasionales, incluyendo requisitos, procedimientos y pol√≠ticas aplicables",
  "reasoning": "Consulta sobre proceso operacional que requiere acceso a documentaci√≥n interna de pol√≠ticas y procedimientos"
}

### Ejemplo NONE - Interacci√≥n social:
Input: "Hola, ¬øc√≥mo est√°s?"
Output: {
  "requiresSearch": false,
  "toolType": "NONE",
  "enhancedInstruction": "",
  "reasoning": "Saludo social que no requiere b√∫squeda de informaci√≥n ni uso de herramientas"
}

## INSTRUCCIONES FINALES
1. Analiza cuidadosamente cada palabra clave en la consulta
2. Identifica el tipo de informaci√≥n solicitada
3. Selecciona la herramienta m√°s apropiada seg√∫n las reglas
4. Genera instrucciones espec√≠ficas y accionables
5. Mant√©n el reasoning breve pero informativo

## CRITICO
- RESPONDER EN EL FORMATO JSON EXACTAMENTE COMO SE INDICA
- NO PUEDES OMITIR CARACTERES IMPORTANTE DEL FORMATO, COMO LAS LLAVES {} ' ,

Ahora analiza la consulta proporcionada y responde con el JSON estructurado.
`;

    const llmProvider = GoogleGenAIManager.getProvider(centerId, firestore);

    const response = await llmProvider.generateContent({
      prompt: analysisPrompt,
      config: {
        temperature: 0.3, // M√°s flexibilidad para generar respuestas
        maxOutputTokens: 500, // M√°s espacio para JSON y explicaci√≥n
        topK: 40,
        topP: 0.8,
      },
    });

    try {
      // Extraer JSON de la respuesta
      const jsonMatch = response.text?.match(/\{[\s\S]*\}/);
      if (!jsonMatch) {
        throw new Error("No se encontr√≥ JSON v√°lido en respuesta");
      }
      const analysis = JSON.parse(jsonMatch[0]);
      console.log(
        `üîç An√°lisis de intenci√≥n: ${JSON.stringify(analysis, null, 2)}`
      );
      return {
        requiresSearch: analysis.requiresSearch || false,
        toolType: analysis.toolType || "NONE",
        enhancedInstruction: analysis.enhancedInstruction || undefined,
        reasoning: analysis.reasoning || "Sin raz√≥n especificada",
      };
    } catch (parseError) {
      console.error(
        "‚ùå IntentionInterpreter: Error parseando respuesta LLM:",
        parseError
      );
      // Fallback simple si falla el parsing
      const isObviousCasual =
        /^(hola|hi|buenos d√≠as|buenas tardes|gracias|ok|bien|mal)$/i.test(
          prompt.trim()
        );
      return {
        requiresSearch: !isObviousCasual,
        toolType: isObviousCasual ? "NONE" : "INTERNAL",
        enhancedInstruction: isObviousCasual
          ? undefined
          : `Busca informaci√≥n operacional relacionada con: ${prompt}`,
        reasoning: "Fallback por error de parsing",
      };
    }
  }

  /**
   * Traduce y perfecciona el prompt del usuario actuando como intermediario inteligente
   * @param originalPrompt Prompt original del usuario
   * @param centerId ID del centro para LLM
   * @param availableTools Todas las herramientas disponibles (internas + MCP)
   * @param history Historial de conversaci√≥n
   * @param firestore Instancia de Firestore
   * @returns Prompt perfeccionado listo para el LLM
   */
  static async translateAndPerfect(
    originalPrompt: string,
    centerId: string,
    availableTools: any[] = [],
    history: ChatMessage[] = [],
    firestore?: Firestore
  ): Promise<string> {
    try {
      console.log(
        `üîÑ IntentionInterpreter: Traduciendo y perfeccionando "${originalPrompt}"`
      );

      const translatedPrompt = await this.performTranslation(
        originalPrompt,
        centerId,
        availableTools,
        history,
        firestore
      );

      console.log(
        `‚úÖ IntentionInterpreter: Prompt perfeccionado generado`
      );

      return translatedPrompt;
    } catch (error) {
      console.error(
        `‚ùå IntentionInterpreter: Error en traducci√≥n, usando prompt original:`,
        error
      );
      // Fallback: devolver el prompt original con instrucciones b√°sicas
      return `${originalPrompt}

## ROL Y CONTEXTO
Eres un asistente especializado en log√≠stica de reparto. Responde de manera clara y √∫til bas√°ndote en tu conocimiento y las herramientas disponibles.

Consulta del usuario: ${originalPrompt}`;
    }
  }

  /**
   * Realiza la traducci√≥n inteligente del prompt usando LLM
   */
  private static async performTranslation(
    originalPrompt: string,
    centerId: string,
    availableTools: any[],
    history: ChatMessage[],
    firestore?: Firestore
  ): Promise<string> {
    // Construir contexto conversacional
    const recentContext = history
      ?.slice(-5)
      .map(
        (msg) =>
          `${msg.role === "user" ? "Usuario" : "Asistente"}: ${msg.content}`
      )
      .join("\n") || "Sin historial previo";

    // Separar herramientas por tipo
    const internalTools = availableTools.filter(tool => tool.name === "buscar_informacion_operacional");
    const mcpTools = availableTools.filter(tool => tool.name !== "buscar_informacion_operacional");

    // Construir lista de herramientas disponibles
    const toolsList = [
      ...internalTools.map(tool => `- ${tool.name}: ${tool.description} (INTERNA)`),
      ...mcpTools.map(tool => `- ${tool.name}: ${tool.description} (MCP)`)
    ].join("\n") || "No hay herramientas disponibles";

    const translationPrompt = `
Eres un TRADUCTOR INTELIGENTE especializado en convertir consultas de usuarios en prompts perfectos para un LLM de log√≠stica.

## CONTEXTO CONVERSACIONAL RECIENTE
${recentContext}

## HERRAMIENTAS DISPONIBLES
${toolsList}

## TU MISI√ìN
Toma la consulta del usuario y cr√©a un prompt perfeccionado que:
1. **Interprete la intenci√≥n real** considerando el contexto conversacional
2. **Identifique qu√© herramientas usar** y c√≥mo usarlas
3. **Proporcione instrucciones claras** al LLM sobre c√≥mo responder
4. **Maneje la continuidad conversacional** (referencias como "ahora", "tambi√©n", etc.)

## CONSULTA DEL USUARIO A TRADUCIR
"${originalPrompt}"

## REGLAS DE TRADUCCI√ìN

### PARA HERRAMIENTAS INTERNAS (Documentaci√≥n):
- Si la consulta requiere informaci√≥n de procesos, pol√≠ticas o procedimientos
- Instr√∫yele que use "buscar_informacion_operacional" 
- P√≠dele una respuesta COMPLETA y DETALLADA
- NO mencionar tarjetas

### PARA HERRAMIENTAS MCP (Datos din√°micos):
- Si la consulta requiere datos espec√≠ficos, m√©tricas o rendimientos
- Instr√∫yele qu√© herramienta MCP usar con qu√© par√°metros
- P√≠dele un AN√ÅLISIS conciso 
- Que termine invitando a ver las tarjetas

### PARA CONSULTAS CONVERSACIONALES:
- Si son saludos, agradecimientos o conversaci√≥n casual
- Instr√∫yele que responda naturalmente sin herramientas

## FORMATO DE RESPUESTA
Devuelve √öNICAMENTE el prompt perfeccionado listo para ser usado por el LLM, sin explicaciones adicionales.

El prompt debe incluir:
- Rol y contexto del LLM
- La acci√≥n espec√≠fica a realizar
- Instrucciones sobre herramientas si aplica
- Gu√≠a sobre el tipo de respuesta esperada
`;

    const llmProvider = GoogleGenAIManager.getProvider(centerId, firestore);
    const response = await llmProvider.generateContent({
      prompt: translationPrompt,
      trackTokens: false,
      config: {
        temperature: 0.4,
        maxOutputTokens: 800,
        topK: 30,
        topP: 0.9,
      },
    });

    return response.text || `${originalPrompt}

Eres un asistente de log√≠stica. Responde √∫tilmente.`;
  }
}
